#!/usr/bin/env python3
"""
Apply macOS Finder tags to folders based on a TSV inventory.

This tool is designed for safe, non-destructive organization:
- It only writes Finder tag metadata (xattr _kMDItemUserTags).
- It never deletes or moves files.

Tag model:
- Primary (mutually exclusive): dev OK / dev MAY / dev NO
- Secondary (additive): dev WEB

By default this is a DRY RUN. Use --apply to actually write tags.
"""

from __future__ import annotations

import argparse
import csv
import hashlib
import json
import os
import plistlib
import subprocess
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple


XATTR_KEY = "com.apple.metadata:_kMDItemUserTags"

PRIMARY_TAGS = ("dev OK", "dev MAY", "dev NO")
SECONDARY_TAGS = ("dev WEB",)

TAG_COLOR: Dict[str, int] = {
    "dev OK": 2,   # green
    "dev MAY": 7,  # orange
    "dev NO": 6,   # red
    "dev WEB": 4,  # blue
}


def _run(cmd: List[str], timeout: int = 20) -> Tuple[int, str, str]:
    p = subprocess.run(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
        timeout=timeout,
    )
    return p.returncode, p.stdout, p.stderr


def _get_tags(path: str) -> List[str]:
    rc, out, _ = _run(["xattr", "-px", XATTR_KEY, path], timeout=5)
    if rc != 0:
        return []
    hex_bytes = "".join(out.split())
    if not hex_bytes:
        return []
    try:
        raw = bytes.fromhex(hex_bytes)
        tags = plistlib.loads(raw)
        if isinstance(tags, list):
            return [t for t in tags if isinstance(t, str)]
        return []
    except Exception:
        return []


def _set_tags(path: str, tags: List[str]) -> None:
    raw = plistlib.dumps(tags, fmt=plistlib.FMT_BINARY)
    hex_bytes = raw.hex()
    rc, _, err = _run(["xattr", "-wx", XATTR_KEY, hex_bytes, path], timeout=10)
    if rc != 0:
        raise RuntimeError(err.strip() or "xattr write failed")


def _tag_entry(tag: str) -> str:
    color = TAG_COLOR[tag]
    return f"{tag}\n{color}"


def _strip_primary(tags: List[str]) -> List[str]:
    out: List[str] = []
    for t in tags:
        base = t.split("\n", 1)[0]
        if base in PRIMARY_TAGS:
            continue
        out.append(t)
    return out


def _ensure(tags: List[str], entry: str) -> List[str]:
    if entry in tags:
        return tags
    return tags + [entry]


def _hash_list(tags: List[str]) -> str:
    h = hashlib.sha256()
    for t in tags:
        h.update(t.encode("utf-8", errors="replace"))
        h.update(b"\0")
    return h.hexdigest()


@dataclass(frozen=True)
class Row:
    path: str
    primary: str
    is_web: int


def _load_rows(tsv_path: Path, primary_col: str, is_web_col: str) -> List[Row]:
    rows: List[Row] = []
    with tsv_path.open("r", encoding="utf-8", errors="replace") as f:
        r = csv.DictReader(f, delimiter="\t")
        for rec in r:
            p = (rec.get("path") or "").strip()
            primary = (rec.get(primary_col) or "").strip()
            is_web = (rec.get(is_web_col) or "").strip()
            if not p or primary not in PRIMARY_TAGS:
                continue
            try:
                iw = int(is_web) if is_web else 0
            except Exception:
                iw = 0
            rows.append(Row(path=p, primary=primary, is_web=iw))
    return rows


def main() -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument("--tsv", required=True, help="Inventory TSV generated by dev_repo_inventory.py")
    ap.add_argument("--primary-col", default="tag_suggest")
    ap.add_argument("--is-web-col", default="is_web")
    ap.add_argument("--log", default="", help="Optional JSONL log path (append)")
    ap.add_argument("--report", default="", help="Optional TSV report path")
    ap.add_argument("--max", type=int, default=0)
    ap.add_argument("--apply", action="store_true", help="Actually write tags (default: dry-run)")
    ns = ap.parse_args()

    tsv_path = Path(os.path.expanduser(ns.tsv))
    rows = _load_rows(tsv_path, ns.primary_col, ns.is_web_col)
    if ns.max and ns.max > 0:
        rows = rows[: ns.max]

    ts = time.strftime("%Y-%m-%dT%H:%M:%S%z")
    logf = open(os.path.expanduser(ns.log), "a", encoding="utf-8") if ns.log else None
    repf = open(os.path.expanduser(ns.report), "w", encoding="utf-8") if ns.report else None
    if repf:
        repf.write("path\tprimary\tis_web\tresult\n")

    applied = 0
    skipped = 0
    failed = 0

    try:
        for row in rows:
            try:
                if not os.path.exists(row.path):
                    if repf:
                        repf.write(f"{row.path}\t{row.primary}\t{row.is_web}\tMISSING\n")
                    skipped += 1
                    continue

                before = _get_tags(row.path)
                base = _strip_primary(before)
                after = base + [_tag_entry(row.primary)]
                if row.is_web:
                    after = _ensure(after, _tag_entry("dev WEB"))

                if _hash_list(before) == _hash_list(after):
                    if repf:
                        repf.write(f"{row.path}\t{row.primary}\t{row.is_web}\tNOCHANGE\n")
                    skipped += 1
                    continue

                if ns.apply:
                    _set_tags(row.path, after)
                    applied += 1
                    result = "APPLIED"
                else:
                    skipped += 1
                    result = "DRYRUN"

                if repf:
                    repf.write(f"{row.path}\t{row.primary}\t{row.is_web}\t{result}\n")

                if logf:
                    logf.write(
                        json.dumps(
                            {
                                "ts": ts,
                                "action": "finder_tags_apply",
                                "apply": bool(ns.apply),
                                "path": row.path,
                                "primary": row.primary,
                                "is_web": row.is_web,
                                "before": before,
                                "after": after,
                            },
                            ensure_ascii=True,
                        )
                        + "\n"
                    )
            except Exception as e:
                failed += 1
                if repf:
                    repf.write(f"{row.path}\t{row.primary}\t{row.is_web}\tFAILED\n")
                if logf:
                    logf.write(
                        json.dumps(
                            {
                                "ts": ts,
                                "action": "finder_tags_apply_failed",
                                "path": row.path,
                                "primary": row.primary,
                                "is_web": row.is_web,
                                "error": str(e),
                            },
                            ensure_ascii=True,
                        )
                        + "\n"
                    )
    finally:
        if logf:
            logf.close()
        if repf:
            repf.close()

    print(f"rows={len(rows)} applied={applied} skipped={skipped} failed={failed} apply={int(ns.apply)}")
    return 0 if failed == 0 else 1


if __name__ == "__main__":
    raise SystemExit(main())

